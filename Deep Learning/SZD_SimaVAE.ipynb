{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOYlPts3tisxHM+W7kdKM+r"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"W_niAAo7DL9x","executionInfo":{"status":"ok","timestamp":1664616944707,"user_tz":-120,"elapsed":3078,"user":{"displayName":"Norbert Neumann","userId":"16010244964456960411"}}},"outputs":[],"source":["import os\n","from PIL import Image\n","import numpy as np\n","import json\n","import random\n","import torch"]},{"cell_type":"code","source":["def fetch_arc_tasks(directory):\n","  data = []\n","  MAX_LENGTH = 30\n","  os.chdir(directory)\n","  files = [f for f in os.listdir() if f.endswith('json')]\n","  for f in files:\n","    with open(f, 'r') as file:\n","      json_file = json.loads(file.read())\n","      inputs = [one_hot_encode(np.array(train_exmaples['input'])) for train_exmaples in json_file['train']]\n","      outputs = [one_hot_encode(np.array(train_exmaples['output'])) for train_exmaples in json_file['train']]\n","      test_input = [one_hot_encode(np.array(train_exmaples['input'])) for train_exmaples in json_file['test']]\n","      test_output = [one_hot_encode(np.array(train_exmaples['output'])) for train_exmaples in json_file['test']]\n","      data.append(ARC_Task(inputs, outputs, test_input[0], test_output[0]))\n","\n","  return data\n","\n","def fetch_1d(directory):\n","  data = []\n","  MAX_LENGTH = 30\n","  os.chdir(directory)\n","  files = [f for f in os.listdir() if f.endswith('json')]\n","  for f in files:\n","    with open(f, 'r') as file:\n","      json_file = json.loads(file.read())\n","      inputs = [one_hot_encode(np.array(train_exmaples['input'])) for train_exmaples in json_file['train']]\n","      outputs = [one_hot_encode(np.array(train_exmaples['output'])) for train_exmaples in json_file['train']]\n","      test_input = [one_hot_encode(np.array(train_exmaples['input'])) for train_exmaples in json_file['test']]\n","      test_output = [one_hot_encode(np.array(train_exmaples['output'])) for train_exmaples in json_file['test']]\n","      data.append([x for x in inputs])\n","      data.append([x for x in outputs])\n","      data.append([x for x in test_input])\n","      data.append([x for x in test_output])\n","\n","  random.shuffle(data)\n","  return data\n","\n","def one_hot_encode(array):\n","  MAX_LENGTH = 30\n","  arr = torch.zeros((MAX_LENGTH, MAX_LENGTH, 11))\n","  size = array.shape\n","  for x in range(MAX_LENGTH):\n","    for y in range(MAX_LENGTH):\n","      if x < size[0] and y < size[1]:\n","        arr[x, y, array[x, y]] = 1\n","      else:\n","        arr[x, y, 10] = 1\n","  return arr.flatten()"],"metadata":{"id":"y0D66HSPFadA","executionInfo":{"status":"ok","timestamp":1664624160009,"user_tz":-120,"elapsed":296,"user":{"displayName":"Norbert Neumann","userId":"16010244964456960411"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["from matplotlib.pyplot import imshow\n","%matplotlib inline\n","\n","def collapse(tensor):\n","  arr = np.zeros((30, 30))\n","  for x in range(30):\n","    for y in range(30):\n","      arr[x, y] = torch.argmax(tensor[x, y]).item()\n","  return arr\n","\n","def visualize(tensor):\n","  #torch.argmax(tensor.reshape(30, 30, 11)).item()\n","  arr = np.zeros((30, 30))\n","  for x in range(30):\n","    for y in range(30):\n","      arr[x, y] = torch.argmax(tensor[x, y]).item()\n","  convert(arr)\n","\n","def visualize2(tensor):\n","  arr = np.zeros((30, 30))\n","  for x in range(30):\n","    for y in range(30):\n","      difs = [torch.abs(v - tensor[x, y]) for v in color2vector]\n","      sums = [torch.sum(difs[i]) for i in range(11)]\n","      index_min = min(range(len(sums)), key=sums.__getitem__)\n","      #print(index_min)\n","      arr[x, y] = index_min\n","  convert(arr)\n","\n","converter = {}\n","converter[0] = np.array([0, 0, 0])\n","converter[1] = np.array([0, 116, 217])\n","converter[2] = np.array([255, 65, 54])\n","converter[3] = np.array([46, 204, 64])\n","converter[4] = np.array([255, 220, 0])\n","converter[5] = np.array([170, 170, 170])\n","converter[6] = np.array([240, 18, 190])\n","converter[7] = np.array([255, 113, 27])\n","converter[8] = np.array([127, 219, 255])\n","converter[9] = np.array([135, 12, 37])\n","converter[10] = np.array([255, 255, 255])\n","\n","def convert(X):\n","  Y = np.zeros(shape=(X.shape[0], X.shape[1], 3), dtype=np.uint8)\n","  for x in range(X.shape[0]):\n","    for y in range(X.shape[1]):\n","      Y[x, y] = converter[X[x, y]]\n","  imshow(Y)"],"metadata":{"id":"EN2ET6P-Sz3I","executionInfo":{"status":"ok","timestamp":1664623546102,"user_tz":-120,"elapsed":255,"user":{"displayName":"Norbert Neumann","userId":"16010244964456960411"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["class ARC_Task:\n","  def __init__(self, inputs, outputs, test_input, test_output):\n","    self.inputs = inputs\n","    self.outputs = outputs\n","    self.test_input = test_input\n","    self.test_output = test_output"],"metadata":{"id":"K-ZsezTMEWvE","executionInfo":{"status":"ok","timestamp":1664616944710,"user_tz":-120,"elapsed":9,"user":{"displayName":"Norbert Neumann","userId":"16010244964456960411"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import Dataset\n","\n","class ARCDataset(Dataset):\n","  def __init__(self, data):\n","    self.data = data\n","\n","  def __getitem__(self, idx):\n","    return self.data[idx]\n","\n","  def __len__(self):\n","    return len(self.data)"],"metadata":{"id":"Cu0NXtjJFlvp","executionInfo":{"status":"ok","timestamp":1664616944711,"user_tz":-120,"elapsed":9,"user":{"displayName":"Norbert Neumann","userId":"16010244964456960411"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class VAE(nn.Module):\n","  def __init__(self, input_shape=30*30*11, latent_dim = 128):\n","    super(VAE, self).__init__()\n","    self.input_shape = input_shape\n","    self.latent_dim = latent_dim\n","\n","    self.encoder_l1 = nn.Linear(self.input_shape, 64, bias=True)\n","    self.fc1 = nn.Linear(64, 128)\n","    self.fc_mu = nn.Linear(128, latent_dim)\n","    self.fc_log_var = nn.Linear(128, latent_dim)\n","    self.fc2 = nn.Linear(latent_dim, 64)\n","    self.decoder_l1 = nn.Linear(64, self.input_shape, bias=True)\n","\n","  def reparameterize(self, mu, log_var):\n","    std = torch.exp(0.5 * log_var)\n","    eps = torch.randn_like(std)\n","    sample = mu + (eps * std)\n","    return sample\n","\n","  def forward(self, x):\n","    task_vector = torch.zeros((1, 64))\n","    mu_acc = torch.zeros((1, self.latent_dim))\n","    log_var_acc = torch.zeros((1, self.latent_dim))\n","    for input, output in zip(task.inputs, task.outputs):\n","      latent_input, mu_input, log_var_input = self.run_encoder(input)\n","      latent_output, mu_output, log_var_output = self.run_encoder(output)\n","      task_vector += latent_output - latent_input\n","      mu_acc += mu_output - mu_input\n","      log_var_acc += log_var_output - log_var_input\n","    task_vector /= len(task.inputs)\n","    mu = mu_acc / len(task.inputs)\n","    log_var = log_var_acc / len(task.inputs)\n","    latent_prediction, _, _ = self.run_encoder(task.test_input)\n","    prediction = self.run_decoder(latent_prediction + task_vector)\n","    return prediction, mu, log_var\n","\n","  def run_encoder(self, x):\n","    x = torch.sigmoid(self.encoder_l1(x))\n","    hidden = self.fc1(x)\n","    mu = self.fc_mu(hidden)\n","    log_var = self.fc_log_var(hidden)\n","\n","    z = self.reparameterize(mu, log_var)\n","    z = self.fc2(z) # latent\n","    return z, mu, log_var\n","\n","  def run_decoder(self, latent):\n","    reconstruction = torch.sigmoid(self.decoder_l1(latent))\n","    return reconstruction"],"metadata":{"id":"3DNUxfRkDSq6","executionInfo":{"status":"ok","timestamp":1664616945048,"user_tz":-120,"elapsed":3,"user":{"displayName":"Norbert Neumann","userId":"16010244964456960411"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class Undirect_VAE(nn.Module):\n","  def __init__(self, input_shape=30*30*11, latent_dim = 128):\n","    super(Undirect_VAE, self).__init__()\n","    self.input_shape = input_shape\n","    self.latent_dim = latent_dim\n","\n","    self.encoder_l1 = nn.Linear(self.input_shape, 64, bias=True)\n","    self.fc1 = nn.Linear(64, 128)\n","    self.fc_mu = nn.Linear(128, latent_dim)\n","    self.fc_log_var = nn.Linear(128, latent_dim)\n","    self.fc2 = nn.Linear(latent_dim, 64)\n","    self.decoder_l1 = nn.Linear(64, self.input_shape, bias=True)\n","\n","  def reparameterize(self, mu, log_var):\n","    std = torch.exp(0.5 * log_var)\n","    eps = torch.randn_like(std)\n","    sample = mu + (eps * std)\n","    return sample\n","\n","  def forward(self, x):\n","    latent, mu, log_var = self.run_encoder(x)\n","    prediction = self.run_decoder(latent)\n","    return prediction, mu, log_var\n","\n","  def run_encoder(self, x):\n","    x = torch.sigmoid(self.encoder_l1(x))\n","    hidden = self.fc1(x)\n","    mu = self.fc_mu(hidden)\n","    log_var = self.fc_log_var(hidden)\n","\n","    z = self.reparameterize(mu, log_var)\n","    z = self.fc2(z) # latent\n","    return z, mu, log_var\n","\n","  def run_decoder(self, latent):\n","    reconstruction = torch.sigmoid(self.decoder_l1(latent))\n","    return reconstruction"],"metadata":{"id":"-b6GZv1DUY9x","executionInfo":{"status":"ok","timestamp":1664624232428,"user_tz":-120,"elapsed":271,"user":{"displayName":"Norbert Neumann","userId":"16010244964456960411"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["def final_loss(loss, mu, log_var):\n","  KLD = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n","  return KLD + loss"],"metadata":{"id":"3Gh2HDUFEYCX","executionInfo":{"status":"ok","timestamp":1664616947055,"user_tz":-120,"elapsed":249,"user":{"displayName":"Norbert Neumann","userId":"16010244964456960411"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["train_dataset = ARCDataset(fetch_1d(\"/content/train\"))\n","len(train_dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SkHroUzHFfyQ","executionInfo":{"status":"ok","timestamp":1664624197397,"user_tz":-120,"elapsed":19113,"user":{"displayName":"Norbert Neumann","userId":"16010244964456960411"}},"outputId":"cffdc88c-f986-40ca-feda-b854d439b444"},"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1600"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["model = Undirect_VAE(latent_dim=500)\n","model.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9oZd4xyQFh74","executionInfo":{"status":"ok","timestamp":1664625574487,"user_tz":-120,"elapsed":255,"user":{"displayName":"Norbert Neumann","userId":"16010244964456960411"}},"outputId":"003e553c-e0eb-4c85-88ee-89e8556cfd17"},"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Undirect_VAE(\n","  (encoder_l1): Linear(in_features=9900, out_features=64, bias=True)\n","  (fc1): Linear(in_features=64, out_features=128, bias=True)\n","  (fc_mu): Linear(in_features=128, out_features=500, bias=True)\n","  (fc_log_var): Linear(in_features=128, out_features=500, bias=True)\n","  (fc2): Linear(in_features=500, out_features=64, bias=True)\n","  (decoder_l1): Linear(in_features=64, out_features=9900, bias=True)\n",")"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":["import torch.optim as optim\n","\n","mse = nn.MSELoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.0001)\n","n_epochs = 500\n","\n","for epoch in range(n_epochs):\n","  loss = 0\n","\n","  for task in train_dataset:\n","    optimizer.zero_grad()\n","    prediction, mu, log_var = model(task)\n","    mse_loss = mse(prediction, task.test_output)\n","    train_loss = final_loss(mse_loss, mu, log_var)\n","    train_loss.backward()\n","    optimizer.step()\n","    loss += train_loss.item()\n","\n","  if epoch % 5 == 0:\n","    print(epoch, loss)"],"metadata":{"id":"umLYE4SwF0jl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch.optim as optim\n","\n","mse = nn.MSELoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.00001)\n","n_epochs = 50\n","\n","for epoch in range(n_epochs):\n","  loss = 0\n","\n","  for task in train_dataset[0:400]:\n","    optimizer.zero_grad()\n","    prediction, mu, log_var = model(task[0])\n","    mse_loss = mse(prediction, task[0])\n","    train_loss = final_loss(mse_loss, mu, log_var)\n","    train_loss.backward()\n","    optimizer.step()\n","    loss += train_loss.item()\n","\n","  if epoch % 5 == 0:\n","    print(epoch, loss)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T-vZGSq2Vj26","outputId":"f2fee5c9-3a07-4667-831b-6969b596b941"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0 7.5084149478934705\n","5 7.516920574940741\n","10 7.5167934987694025\n","15 7.517750315833837\n","20 7.51696885516867\n","25 7.516352977603674\n"]}]},{"cell_type":"code","source":["visualize(train_dataset[1][0].reshape(30, 30, 11))"],"metadata":{"id":"G3lX1cdCt1Yb","colab":{"base_uri":"https://localhost:8080/","height":266},"executionInfo":{"status":"ok","timestamp":1664625550262,"user_tz":-120,"elapsed":406,"user":{"displayName":"Norbert Neumann","userId":"16010244964456960411"}},"outputId":"8608f137-d269-4dbc-9d9f-7078a13a2698"},"execution_count":37,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["def predict_first_test(task):\n","  task_vector = torch.zeros(500)\n","  for input, output in zip(task.inputs, task.outputs):\n","    latent_input = model.run_encoder(one_hot_encode(input))\n","    latent_output = model.run_encoder(one_hot_encode(output))\n","    task_vector += latent_output - latent_input\n","  task_vector /= len(task.inputs)\n","  latent_prediction = model.run_encoder(one_hot_encode(task.test_inputs[0])) + task_vector\n","  return model.run_decoder(latent_prediction)"],"metadata":{"id":"xY25mBQ4S6va"},"execution_count":null,"outputs":[]}]}