{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOAt8+7oauLrrDok7y7K89q"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"e5vWHClzMHqU","executionInfo":{"status":"ok","timestamp":1664101730184,"user_tz":-120,"elapsed":2498,"user":{"displayName":"Norbert Neumann","userId":"16010244964456960411"}}},"outputs":[],"source":["import os\n","from PIL import Image\n","import numpy as np\n","import json\n","import random\n","import torch"]},{"cell_type":"code","source":["class ARC_Task:\n","  def __init__(self, inputs, outputs, test_input, test_output):\n","    self.inputs = inputs\n","    self.outputs = outputs\n","    self.test_input = test_input\n","    self.test_output = test_output"],"metadata":{"id":"_49wYuhaMRdC","executionInfo":{"status":"ok","timestamp":1664101730189,"user_tz":-120,"elapsed":31,"user":{"displayName":"Norbert Neumann","userId":"16010244964456960411"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["from matplotlib.pyplot import imshow\n","%matplotlib inline\n","\n","def visualize(tensor):\n","  #torch.argmax(tensor.reshape(30, 30, 11)).item()\n","  arr = np.zeros((30, 30))\n","  for x in range(30):\n","    for y in range(30):\n","      arr[x, y] = torch.argmax(tensor[x, y]).item()\n","  convert(arr)\n","\n","def visualize2(tensor):\n","  arr = np.zeros((30, 30))\n","  for x in range(30):\n","    for y in range(30):\n","      difs = [torch.abs(v - tensor[x, y]) for v in color2vector]\n","      sums = [torch.sum(difs[i]) for i in range(11)]\n","      index_min = min(range(len(sums)), key=sums.__getitem__)\n","      #print(index_min)\n","      arr[x, y] = index_min\n","  convert(arr)\n","\n","converter = {}\n","converter[0] = np.array([0, 0, 0])\n","converter[1] = np.array([0, 116, 217])\n","converter[2] = np.array([255, 65, 54])\n","converter[3] = np.array([46, 204, 64])\n","converter[4] = np.array([255, 220, 0])\n","converter[5] = np.array([170, 170, 170])\n","converter[6] = np.array([240, 18, 190])\n","converter[7] = np.array([255, 113, 27])\n","converter[8] = np.array([127, 219, 255])\n","converter[9] = np.array([135, 12, 37])\n","converter[10] = np.array([255, 255, 255])\n","\n","def convert(X):\n","  Y = np.zeros(shape=(X.shape[0], X.shape[1], 3), dtype=np.uint8)\n","  for x in range(X.shape[0]):\n","    for y in range(X.shape[1]):\n","      Y[x, y] = converter[X[x, y]]\n","  imshow(Y)"],"metadata":{"id":"1el9VmUIMTAW","executionInfo":{"status":"ok","timestamp":1664101746327,"user_tz":-120,"elapsed":450,"user":{"displayName":"Norbert Neumann","userId":"16010244964456960411"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["def fetch(directory):\n","  data = []\n","  MAX_LENGTH = 30\n","  os.chdir(directory)\n","  files = [f for f in os.listdir() if f.endswith('json')]\n","  for f in files:\n","    with open(f, 'r') as file:\n","      json_file = json.loads(file.read())\n","      inputs = [one_hot_encode_3d(np.array(train_exmaples['input'])) for train_exmaples in json_file['train']]\n","      outputs = [one_hot_encode_3d(np.array(train_exmaples['output'])) for train_exmaples in json_file['train']]\n","      test_input = [one_hot_encode_3d(np.array(train_exmaples['input'])) for train_exmaples in json_file['test']]\n","      test_output = [one_hot_encode_3d(np.array(train_exmaples['output'])) for train_exmaples in json_file['test']]\n","      data.append(ARC_Task(inputs, outputs, test_input[0], test_output[0]))\n","\n","  return data\n","\n","def one_hot_encode(array):\n","  MAX_LENGTH = 30\n","  arr = torch.zeros((MAX_LENGTH, MAX_LENGTH, 11))\n","  size = array.shape\n","  for x in range(MAX_LENGTH):\n","    for y in range(MAX_LENGTH):\n","      if x < size[0] and y < size[1]:\n","        arr[x, y, array[x, y]] = 1\n","      else:\n","        arr[x, y, 10] = 1\n","  return arr.flatten()\n","\n","def one_hot_encode_3d(array):\n","  MAX_LENGTH = 30\n","  arr = torch.zeros((MAX_LENGTH, MAX_LENGTH, 11))\n","  size = array.shape\n","  for x in range(MAX_LENGTH):\n","    for y in range(MAX_LENGTH):\n","      if x < size[0] and y < size[1]:\n","        arr[x, y, array[x, y]] = 1\n","      else:\n","        arr[x, y, 10] = 1\n","  return arr.reshape((11, MAX_LENGTH, MAX_LENGTH))"],"metadata":{"id":"mnC5l7zOMYEM","executionInfo":{"status":"ok","timestamp":1664101748692,"user_tz":-120,"elapsed":22,"user":{"displayName":"Norbert Neumann","userId":"16010244964456960411"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import Dataset\n","\n","class ARCDataset(Dataset):\n","  def __init__(self, data):\n","    self.data = data\n","\n","  def __getitem__(self, idx):\n","    return self.data[idx]\n","\n","  def __len__(self):\n","    return len(self.data)"],"metadata":{"id":"KvvsyktCMYu2","executionInfo":{"status":"ok","timestamp":1664101756868,"user_tz":-120,"elapsed":621,"user":{"displayName":"Norbert Neumann","userId":"16010244964456960411"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class ConvVAE(nn.Module):\n","  def __init__(self, image_channels = 11, kernel_size = 3,\n","               latent_dim = 200, init_channels = 8):\n","    super(ConvVAE, self).__init__()\n","    self.latent_dim = latent_dim\n","    self.enc1 = nn.Conv2d(\n","        in_channels=image_channels, out_channels=init_channels, \n","        kernel_size=kernel_size, stride=2, padding=1\n","    )\n","    self.enc2 = nn.Conv2d(\n","        in_channels=init_channels, out_channels=init_channels*2, \n","        kernel_size=kernel_size, stride=2, padding=1\n","    )\n","    self.enc3 = nn.Conv2d(\n","        in_channels=init_channels*2, out_channels=init_channels*4, \n","        kernel_size=kernel_size, stride=2, padding=1\n","    )\n","    self.enc4 = nn.Conv2d(\n","        in_channels=init_channels*4, out_channels=64, \n","        kernel_size=kernel_size, stride=2, padding=0\n","    )\n","    self.fc1 = nn.Linear(64, 128)\n","    self.fc_mu = nn.Linear(128, latent_dim)\n","    self.fc_log_var = nn.Linear(128, latent_dim)\n","    self.fc2 = nn.Linear(latent_dim, 64)\n","\n","    self.dec1 = nn.ConvTranspose2d(\n","        in_channels=64, out_channels=init_channels*8,\n","        kernel_size=kernel_size, stride=1, padding=0\n","    )\n","    self.dec2 = nn.ConvTranspose2d(\n","        in_channels=init_channels*8, out_channels=init_channels*4,\n","        kernel_size=kernel_size, stride=2, padding=1\n","    )\n","    self.dec3 = nn.ConvTranspose2d(\n","        in_channels=init_channels*4, out_channels=init_channels*2,\n","        kernel_size=kernel_size, stride=2, padding=1\n","    )\n","    self.dec4 = nn.ConvTranspose2d(\n","        in_channels=init_channels*2, out_channels=init_channels*1,\n","        kernel_size=kernel_size, stride=2, padding=1\n","    )\n","\n","\n","  def reparameterize(self, mu, log_var):\n","    std = torch.exp(0.5 * log_var)\n","    eps = torch.randn_like(std)\n","    sample = mu + (eps * std)\n","    return sample\n","\n","  def forward(self, x):\n","    task_vector = torch.zeros((1, 64))\n","    mu_acc = torch.zeros((1, self.latent_dim))\n","    log_var_acc = torch.zeros((1, self.latent_dim))\n","    for input, output in zip(task.inputs, task.outputs):\n","      latent_input, mu_input, log_var_input = self.run_encoder(input)\n","      latent_output, mu_output, log_var_output = self.run_encoder(output)\n","      task_vector += latent_output - latent_input\n","      mu_acc += mu_output - mu_input\n","      log_var_acc += log_var_output - log_var_input\n","    task_vector /= len(task.inputs)\n","    mu = mu_acc / len(task.inputs)\n","    log_var = log_var_acc / len(task.inputs)\n","    latent_prediction, _, _ = self.run_encoder(task.test_input)\n","    prediction = self.run_decoder(latent_prediction + task_vector)\n","    return prediction, mu, log_var\n","\n","  def run_encoder(self, x):\n","    x = F.relu(self.enc1(x))\n","    x = F.relu(self.enc2(x))\n","    x = F.relu(self.enc3(x))\n","    #print(x.size())\n","    x = F.relu(self.enc4(x))\n","    batch, _, _, = x.shape\n","    x = F.adaptive_avg_pool2d(x, 1).reshape(1, -1)\n","    hidden = self.fc1(x)\n","    mu = self.fc_mu(hidden)\n","    log_var = self.fc_log_var(hidden)\n","\n","    z = self.reparameterize(mu, log_var)\n","    z = self.fc2(z) # latent\n","    return z, mu, log_var\n","\n","  def run_decoder(self, x):\n","    x = F.relu(self.dec1(x))\n","    x = F.relu(self.dec2(x))\n","    x = F.relu(self.dec3(x))\n","    reconstruction = torch.sigmoid(self.dec4(x))\n","    return reconstruction"],"metadata":{"id":"19BcrqRgManP","executionInfo":{"status":"ok","timestamp":1664101766603,"user_tz":-120,"elapsed":413,"user":{"displayName":"Norbert Neumann","userId":"16010244964456960411"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def final_loss(loss, mu, log_var):\n","  KLD = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n","  return KLD + loss"],"metadata":{"id":"HJIKKiZNMdF-","executionInfo":{"status":"ok","timestamp":1664101773966,"user_tz":-120,"elapsed":599,"user":{"displayName":"Norbert Neumann","userId":"16010244964456960411"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["train_dataset = ARCDataset(fetch(\"/content/train\"))\n","len(train_dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":304},"id":"ds3qfaWHMe4Z","executionInfo":{"status":"error","timestamp":1664101779569,"user_tz":-120,"elapsed":387,"user":{"displayName":"Norbert Neumann","userId":"16010244964456960411"}},"outputId":"3ec88cef-ed71-42ff-c18a-93558a512b4c"},"execution_count":8,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-8186f37fda41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mARCDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-68ee5ba5009e>\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mMAX_LENGTH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/train'"]}]},{"cell_type":"code","source":["model = ConvVAE()\n","model.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c7avnaYAMgPv","executionInfo":{"status":"ok","timestamp":1664101794552,"user_tz":-120,"elapsed":514,"user":{"displayName":"Norbert Neumann","userId":"16010244964456960411"}},"outputId":"534a9682-53db-4c7c-810d-605ca077c93d"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ConvVAE(\n","  (enc1): Conv2d(11, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","  (enc2): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","  (enc3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","  (enc4): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2))\n","  (fc1): Linear(in_features=64, out_features=128, bias=True)\n","  (fc_mu): Linear(in_features=128, out_features=200, bias=True)\n","  (fc_log_var): Linear(in_features=128, out_features=200, bias=True)\n","  (fc2): Linear(in_features=200, out_features=64, bias=True)\n","  (dec1): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n","  (dec2): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","  (dec3): ConvTranspose2d(32, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","  (dec4): ConvTranspose2d(16, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",")"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["import torch.optim as optim\n","\n","mse = nn.MSELoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.0001)\n","n_epochs = 10\n","\n","for epoch in range(n_epochs):\n","  loss = 0\n","\n","  for task in train_dataset:\n","    optimizer.zero_grad()\n","    reconstruction, mu, log_var = model(task)\n","    mse_loss = mse(prediction, task.test_output)\n","    train_loss = final_loss(mse_loss, mu, log_var)\n","    train_loss.backward()\n","    optimizer.step()\n","    loss += train_loss.item()\n","\n","  if epoch % 5 == 0:\n","    print(epoch, loss)"],"metadata":{"id":"7as8NU05Mj6M"},"execution_count":null,"outputs":[]}]}